# =================================================================
# Dataset Config for Wan2.1 14B I2V (480p) Fine-tuning
# =================================================================

# --- Resolution & Aspect Ratio Bucketing ---
# Target a base resolution compatible with the 480p model.
# Since my training videos are mostly portrait (479x608), I set a base resolution
# that reflects this. Bucketing will handle the slight variations.
# The format is [height, width].

resolutions = [
  [608, 480]
]

# Enable aspect ratio bucketing. This is completely not essential for my dataset as
# all of training videos have same resolution, but I set it to True to make config flexible 
enable_ar_bucket = true

# The range of aspect ratios (width / height) to create buckets for.
# My main aspect ratio is ~0.78 (479/608). This range covers it well.
min_ar = 0.7
max_ar = 0.8

# The number of buckets to divide the aspect ratio range into.
# Actually in my case it's only one bucket with data, other one will be skipped
num_ar_buckets = 2

# --- Frame (Video Length) Bucketing ---
# This is critical for handling videos with variable lengths (up to 5 seconds).
# Buckets are based on a 16 FPS frame rate.
# Max frames = 5 seconds * 16 FPS = 80 frames.
frame_buckets = [48, 64, 80]


# --- Directory Settings ---
# Settings for my dataset containing videos and captions

[[directory]]
# IMPORTANT: Replace this with your path
path = "/data/generation_experiments/train_dataset_v2"

# The number of times the dataset is repeated per epoch.
# In my case I have almost 150 short videos, so I think it will be enough
# So what is why number of repeats is 1
num_repeats = 1

# In my case all videos have captions, but in general case some videos could miss it
# So it's better to set some default prompt
default_caption = "The action presented on screen is pov_anal_missionary"